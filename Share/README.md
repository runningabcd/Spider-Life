1.知乎  用户信息采集  用户关注  访问量  等等  分析用户数据  通过采集的用户头像  分析 网友喜欢的头像

Open cv  average  face  模块

带逛机器人也是  用了  opencv  图像相似度识别加上  用户  信息判断以及  关注数  或者访问量等

2.app下载量追踪，这个主要是抓取 多个app下载商城整合的数据

3.股票特征分析，主要是根据上面六个维度进行综合分析，股票是否适合建仓或者减仓

4.选电影  看ppt上的介绍，  当前有个app已经有了，但是微信公众号还没有

5.什么是爬虫

首先爬虫和我们的生活息息相关，比如  咱们平时用的搜索引擎  google 百度  等等，其实这些搜索引擎背后都是强大的分布式爬虫集群在支持，通过爬虫爬取互联网信息保存下来，然后建档分析建索引等等，最后支持用户通过引擎直接搜索相关信息，展示给用户搜索结果

网络爬虫（英语：web crawler），也叫网络蜘蛛（spider），是一种用来自动浏览万维网的网络机器人（英语：Internet bot）。爬虫是用来获取数据的网络程序，爬虫行为主要是模拟了浏览器和用户行为，比如用户的点击，提交用户名密码等等，部署多个爬虫就可以实现大规模的数据抓取。

既然刚才已经提到爬虫是网络程序，那么爬虫的行为就很好理解了，就像是，我们在浏览器地址栏输入一个网址，浏览器负责帮我们请求相关服务器，等服务器响应之后，页面上就出现我们想知道的结果


咱们下面来看一下传统爬虫：

比如说我们有个网站需要爬取，那么我们先把这个网站放到队列里面，爬虫调度程序负责从队列里面拿到网址，就拿http://weibo.com/ 新浪微博的首页来说吧，然后把网址给爬虫，爬虫请求这个网址之后，发现返回的页面有更多的链接url，这时候爬虫就需要把返回的页面上的所有的url放入到队列里面，文档存入数据库等等，放入队列的时候要去重，这样爬虫就可以知道自己已经爬过哪些页面了，还有哪些页面没有爬取，进而调度模块又开始把链接从队列取出，给爬虫，不断的重复以上动作

传统爬虫大体上运行过程就是这样了

那么爬虫最大的问题是什么呢，毕竟是网络程序，所以socket io是爬虫当前最大的问题，io 可以简单的理解为 input 和  output  输入 输出  就网络而言 IO是对socket流的操作

为什么说是 网络io 是爬虫最大的阻碍呢，那么来看如下

比如当我们在浏览器地址栏输入一个网址，假设请求的这个网址对方服务器响应特别慢，这样我们就需要等待，一直等待，直到页面显示正常内容，

这个就是同步io过程了，因为中间有了阻塞，我们需要一直等待

在以上条件下，若是我们请求的服务器依然很慢，那么我们不在等待，而是写个程序，只要页面加载完成了，程序就通知我们，在这期间，我们可以做一些别的事情，当然这就是异步 io了 主要用了 回调  ，稍后我们会 继续讲回调相关的内容。

既然爬虫最大的阻碍是网络io，那我们应该如何解决网络io带来的问题呢，

提问环节，大家有知道怎么解决这个问题吗，让爬虫更快速的实现爬取更多的页面？

有人可能说 用多线程，多线程确实是个好的解决方案，那么问题来了  线程池

1.多线程的内存开销很大的，这个成本不低

有的同学可能说用线程池解决，线程池也还可以，但是呢，线程池却不能合理利用带宽，造成带宽过剩，线程池一定程度上控制了线程的数量，实现了线程复用，降低了线程的使用成本。但还是没有解决数量的问题，线程池初始化的时候还是要设置一个最小和最大线程数，以及任务队列的长度，自管理只是在设定范围内的动态调整。另外不同的任务可能有不同的并发需求，为了避免互相影响可能需要多个线程池，最后导致的结果就是Java的系统里充斥了大量的线程池。

2.线程属于系统级的处理单元，主要由内核完成调度的，如果开很多的线程，这样就会导致用户态和内核态的频繁的切换上下文，内核的调度貌似是这样的5-800ms 去切换一个线程，这个成本很大的  上下文  主要是保存了  线程的一些程式计数器  比如 cpu执行指令啊  等等 方便线程切换  调度

3.而且还有一个很大的问题，就是很多脚本语言有个GIL，就Python语言而言，GIL全局解释器锁，是在启用多线程的某个方法之后，这个东西才会初始化的，也就是说，只要多线程他才会启动，GIL会导致一个进程下的多线程其实只有一个线程在运行，有人说把这个锁拿掉就行了，但是呢，拿掉之后发现效率还不如没拿掉之前高，而且还无法保证共享资源的安全性，既然拿不掉，是否可以想别的办法解决呢，从而实现 爬虫更快速的实现爬取更多的页面

callback hell就是异步回调函数过多的嵌套，导致代码的可读性下降以及出错率提高。

那好，咱们接下来看下 传统的爬虫框架是怎么解决这个问题的呢，类似node js如何 单线程实现高并发呢，传统的异步网络框架，遇到阻塞的情况下，比如网络阻塞，那么就注册一个回调方法到内核的回调事件队列，然后程序可以继续向下执行了，由内核负责监控当前这个队列，一旦有数据准备好了，就会把数据copy给线程，调用回调函数，回调函数中可能还有阻塞，还会有回调方法，####此时另一个线程就会执行回调函数里面的相关逻辑，这要求程序里面所有的阻塞 都是 异步的，否则很容易 卡住， 出现callback hell 的 各种问题。
综上来看，callback链，容易导致 callback hell等问题，那么是否还有其他方式来解决这个问题呢。

那么 协程来了  协程是一个很古老的概念，比线程还轻量级的线程，内核是不知道协程的存在的，只知道线程。

协程 可以认为是 用户态下的线程。

举个栗子，比如遇到网络阻塞，使用协程就可以让当前的代码段暂停，保存上下文，让出当前线程，等到io事件回来，再找个其他线程恢复当前的片段上下文等，继续执行  协程 保证每个 协程拥有一个单独的stack 因为系统不知道协程的存在，所以切换协程只是在用户态的状态下切换上下文  相比 内核态和核心态的上下文切换，要省去大量成本  用户可以通过关键字自己实现协程切换，省去了写大量的回调函数

由于每一个协程stack 更小的栈空间 内存空间，所以可以创建大量的实例，这样我们就可以实现高并发的请求了，更高效的利用带宽和CPU，就爬虫而言，使用协程还是挺有优势的，避免了callback带来的callback hell 困扰。

好了，到目前为止我们已经实现了高并发，有个问题，对方网站让你轻易爬取数据的，接下来咱们一些反爬虫的手段

常见的反爬虫 手段 有 验证码 ip限制 等等

咱们先看下  验证码


那我们怎么解决这类验证码呢   ocr opencv 机器学习  训练验证码特征库  人工打码等等

12306  这个可以用百度识图来破解

那么验证码是否可以通过DDOS的手段去解决呢，比如一些常用的网站，验证码都是单独一台服务器提供服务的，如果这个服务器无法响应了，是否就可以跳过输入验证码的环节呢。

滑动验证码 可以利用 一些 自动化工具 破解

还有一些相对来说不可破解的反爬虫逻辑  比如 对方系统的业务逻辑限制  普通用户 和 VIP 用户 权限不同 


接下来  我们 看下  反反爬虫逻辑吧

对于 对方有IP限制 咱们可以 采用 IP池去 轮流切换ip去解决
比如 代理服务 VPS+ADSL  这种动态拨号的 解决IP问题

比如一些需要用户登录的页面，咱们可以模拟用户登录，获取cookie  进而进行数据抓取等等

还可以降低访问频率，避免使对方发现是爬虫

讲完 相关对策之后 ，咱们看下  爬虫带来好的影响和坏的影响

好的影响 

所见即所得  只要咱们能在网上看到的数据，基本都能抓取，抓取之后，可以做数据挖掘，建模等等，比如 翻译 语料库的建立  万福金安 机器翻译 歪果仁估计是看不懂的，可以通过搜集语料，动态匹配翻译等等 

坏的 影响 爬虫的高并发导致小的网站崩溃等